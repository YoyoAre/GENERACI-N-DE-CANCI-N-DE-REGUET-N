{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3496,
     "status": "ok",
     "timestamp": 1636855943755,
     "user": {
      "displayName": "2019 Mat FLORES MARTINEZ MONTSERRAT ILIANA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRxdaFeq-wG9Q_cLz0LP59aI7CEeU491266zPs=s64",
      "userId": "15518882085329513130"
     },
     "user_tz": 360
    },
    "id": "R-qzwaHnHUIP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GRU\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkszUofkHZBJ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1636855943756,
     "user": {
      "displayName": "2019 Mat FLORES MARTINEZ MONTSERRAT ILIANA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRxdaFeq-wG9Q_cLz0LP59aI7CEeU491266zPs=s64",
      "userId": "15518882085329513130"
     },
     "user_tz": 360
    },
    "id": "YiyKlhhEHY8C"
   },
   "outputs": [],
   "source": [
    "filename=\"pruebas.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "error",
     "timestamp": 1636855947507,
     "user": {
      "displayName": "2019 Mat FLORES MARTINEZ MONTSERRAT ILIANA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRxdaFeq-wG9Q_cLz0LP59aI7CEeU491266zPs=s64",
      "userId": "15518882085329513130"
     },
     "user_tz": 360
    },
    "id": "u22hqO2_HY0S",
    "outputId": "5eab5dd1-d155-4181-e3da-c41b721971cf"
   },
   "outputs": [],
   "source": [
    "with open(filename,encoding='ISO-8859-1') as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Dj9-GhlwHcUi"
   },
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "start_story = '|'*seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y8O6nSxYHcPx"
   },
   "outputs": [],
   "source": [
    "text=text.lower()\n",
    "text=start_story+text\n",
    "#text=text.replace('\\n\\n\\n\\n\\n', start_story)\n",
    "#text=text.replace('\\n\\n\\n\\n\\n', start_story)\n",
    "text=text.replace('\\n', ' xoxo ')\n",
    "text=re.sub('  +', '. ', text).strip()\n",
    "text=text.replace('..', '.')\n",
    "\n",
    "text=re.sub('([!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~])', r' \\1 ', text)\n",
    "text=re.sub('\\s{2,}', ' ', text)\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BASKosCuHkex"
   },
   "outputs": [],
   "source": [
    "# TOKENIZATION\n",
    "tokenizer = Tokenizer(char_level=False, filters='')\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) +1\n",
    "token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2888,
     "status": "ok",
     "timestamp": 1635956114870,
     "user": {
      "displayName": "2019 Mat VELAZQUEZ MORAN PEDRO",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11392187614295055784"
     },
     "user_tz": 360
    },
    "id": "MQsHVorPHoUC",
    "outputId": "296be74f-98dd-49b3-a22b-b7fe658b43bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 139423 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.utils import np_utils\n",
    "\n",
    "def generate_sequences(token_list, step):\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(0,len(token_list) - seq_length,step):\n",
    "    X.append(token_list[i:i + seq_length])\n",
    "    y.append(token_list[i + seq_length])\n",
    "  #esta funcion lo que hace es convertir un vector en una matriz tipo binaria\n",
    "  y = np_utils.to_categorical(y,num_classes = total_words)\n",
    "\n",
    "  num_seq = len(X)\n",
    "  print('Number of sequences:',num_seq, \"\\n\")\n",
    "\n",
    "  return X,y,num_seq\n",
    "\n",
    "step = 3\n",
    "seq_length = 10\n",
    "X,y,num_seq = generate_sequences(token_list,step)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wc9rJhZEHtqw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "4357/4357 [==============================] - 647s 147ms/step - loss: 5.7211\n",
      "Epoch 2/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 5.3629\n",
      "Epoch 3/250\n",
      "4357/4357 [==============================] - 630s 145ms/step - loss: 5.3547\n",
      "Epoch 4/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 5.8339\n",
      "Epoch 5/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 5.9020\n",
      "Epoch 6/250\n",
      "4357/4357 [==============================] - 634s 146ms/step - loss: 5.8932\n",
      "Epoch 7/250\n",
      "4357/4357 [==============================] - 629s 144ms/step - loss: 5.8476\n",
      "Epoch 8/250\n",
      "4357/4357 [==============================] - 637s 146ms/step - loss: 5.7865\n",
      "Epoch 9/250\n",
      "4357/4357 [==============================] - 638s 146ms/step - loss: 5.7224\n",
      "Epoch 10/250\n",
      "4357/4357 [==============================] - 626s 144ms/step - loss: 5.6616\n",
      "Epoch 11/250\n",
      "4357/4357 [==============================] - 637s 146ms/step - loss: 5.6037\n",
      "Epoch 12/250\n",
      "4357/4357 [==============================] - 634s 145ms/step - loss: 5.5476\n",
      "Epoch 13/250\n",
      "4357/4357 [==============================] - 637s 146ms/step - loss: 5.4968\n",
      "Epoch 14/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 5.4574\n",
      "Epoch 15/250\n",
      "4357/4357 [==============================] - 635s 146ms/step - loss: 5.4167\n",
      "Epoch 16/250\n",
      "4357/4357 [==============================] - 636s 146ms/step - loss: 5.3744\n",
      "Epoch 17/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 5.3407\n",
      "Epoch 18/250\n",
      "4357/4357 [==============================] - 638s 146ms/step - loss: 5.3108\n",
      "Epoch 19/250\n",
      "4357/4357 [==============================] - 636s 146ms/step - loss: 5.2819\n",
      "Epoch 20/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 5.2548\n",
      "Epoch 21/250\n",
      "4357/4357 [==============================] - 636s 146ms/step - loss: 5.2281\n",
      "Epoch 22/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 5.2139\n",
      "Epoch 23/250\n",
      "4357/4357 [==============================] - 617s 142ms/step - loss: 5.1938\n",
      "Epoch 24/250\n",
      "4357/4357 [==============================] - 621s 143ms/step - loss: 5.1754\n",
      "Epoch 25/250\n",
      "4357/4357 [==============================] - 635s 146ms/step - loss: 5.1598\n",
      "Epoch 26/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 5.1497\n",
      "Epoch 27/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 5.1346\n",
      "Epoch 28/250\n",
      "4357/4357 [==============================] - 643s 148ms/step - loss: 5.1212\n",
      "Epoch 29/250\n",
      "4357/4357 [==============================] - 653s 150ms/step - loss: 5.1107\n",
      "Epoch 30/250\n",
      "4357/4357 [==============================] - 648s 149ms/step - loss: 5.0982\n",
      "Epoch 31/250\n",
      "4357/4357 [==============================] - 658s 151ms/step - loss: 5.0922\n",
      "Epoch 32/250\n",
      "4357/4357 [==============================] - 654s 150ms/step - loss: 5.0808s - loss: 5.\n",
      "Epoch 33/250\n",
      "4357/4357 [==============================] - 650s 149ms/step - loss: 5.0755\n",
      "Epoch 34/250\n",
      "4357/4357 [==============================] - 658s 151ms/step - loss: 5.0688\n",
      "Epoch 35/250\n",
      "4357/4357 [==============================] - 654s 150ms/step - loss: 5.0613\n",
      "Epoch 36/250\n",
      "4357/4357 [==============================] - 651s 149ms/step - loss: 5.0553\n",
      "Epoch 37/250\n",
      "4357/4357 [==============================] - 659s 151ms/step - loss: 5.0578\n",
      "Epoch 38/250\n",
      "4357/4357 [==============================] - 652s 150ms/step - loss: 5.0560\n",
      "Epoch 39/250\n",
      "4357/4357 [==============================] - 656s 150ms/step - loss: 5.0536\n",
      "Epoch 40/250\n",
      "4357/4357 [==============================] - 655s 150ms/step - loss: 5.0498\n",
      "Epoch 41/250\n",
      "4357/4357 [==============================] - 657s 151ms/step - loss: 5.0462\n",
      "Epoch 42/250\n",
      "4357/4357 [==============================] - 660s 151ms/step - loss: 5.0457\n",
      "Epoch 43/250\n",
      "4357/4357 [==============================] - 654s 150ms/step - loss: 5.0506\n",
      "Epoch 44/250\n",
      "4357/4357 [==============================] - 649s 149ms/step - loss: 5.0493\n",
      "Epoch 45/250\n",
      "4357/4357 [==============================] - 664s 152ms/step - loss: 5.0491\n",
      "Epoch 46/250\n",
      "4357/4357 [==============================] - 653s 150ms/step - loss: 5.0463\n",
      "Epoch 47/250\n",
      "4357/4357 [==============================] - 652s 150ms/step - loss: 5.0535\n",
      "Epoch 48/250\n",
      "4357/4357 [==============================] - 656s 151ms/step - loss: 5.0506\n",
      "Epoch 49/250\n",
      "4357/4357 [==============================] - 656s 151ms/step - loss: 5.0538\n",
      "Epoch 50/250\n",
      "4357/4357 [==============================] - 659s 151ms/step - loss: 5.0544\n",
      "Epoch 51/250\n",
      "4357/4357 [==============================] - 659s 151ms/step - loss: 5.0580\n",
      "Epoch 52/250\n",
      "4357/4357 [==============================] - 649s 149ms/step - loss: 5.0590\n",
      "Epoch 53/250\n",
      "4357/4357 [==============================] - 658s 151ms/step - loss: 5.0668\n",
      "Epoch 54/250\n",
      "4357/4357 [==============================] - 654s 150ms/step - loss: 5.0689\n",
      "Epoch 55/250\n",
      "4357/4357 [==============================] - 650s 149ms/step - loss: 5.0701\n",
      "Epoch 56/250\n",
      "4357/4357 [==============================] - 662s 152ms/step - loss: 5.0813\n",
      "Epoch 57/250\n",
      "4357/4357 [==============================] - 659s 151ms/step - loss: 5.0837\n",
      "Epoch 58/250\n",
      "4357/4357 [==============================] - 655s 150ms/step - loss: 5.0830\n",
      "Epoch 59/250\n",
      "4357/4357 [==============================] - 655s 150ms/step - loss: 5.0925\n",
      "Epoch 60/250\n",
      "4357/4357 [==============================] - 655s 150ms/step - loss: 5.0906\n",
      "Epoch 61/250\n",
      "4357/4357 [==============================] - 658s 151ms/step - loss: 5.0968\n",
      "Epoch 62/250\n",
      "4357/4357 [==============================] - 664s 152ms/step - loss: 5.0993\n",
      "Epoch 63/250\n",
      "4357/4357 [==============================] - 648s 149ms/step - loss: 5.1075\n",
      "Epoch 64/250\n",
      "4357/4357 [==============================] - 641s 147ms/step - loss: 5.1171\n",
      "Epoch 65/250\n",
      "4357/4357 [==============================] - 640s 147ms/step - loss: 5.1185\n",
      "Epoch 66/250\n",
      "4357/4357 [==============================] - 634s 146ms/step - loss: 5.1256\n",
      "Epoch 67/250\n",
      "4357/4357 [==============================] - 640s 147ms/step - loss: 5.1341\n",
      "Epoch 68/250\n",
      "4357/4357 [==============================] - 635s 146ms/step - loss: 5.1367\n",
      "Epoch 69/250\n",
      "4357/4357 [==============================] - 645s 148ms/step - loss: 5.1435\n",
      "Epoch 70/250\n",
      "4357/4357 [==============================] - 638s 146ms/step - loss: 5.1544\n",
      "Epoch 71/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 5.1653\n",
      "Epoch 72/250\n",
      "4357/4357 [==============================] - 686s 157ms/step - loss: 5.1699\n",
      "Epoch 73/250\n",
      "4357/4357 [==============================] - 624s 143ms/step - loss: 5.1722\n",
      "Epoch 74/250\n",
      "4357/4357 [==============================] - 635s 146ms/step - loss: 5.1809\n",
      "Epoch 75/250\n",
      "4357/4357 [==============================] - 626s 144ms/step - loss: 5.1862\n",
      "Epoch 76/250\n",
      "4357/4357 [==============================] - 628s 144ms/step - loss: 5.1983\n",
      "Epoch 77/250\n",
      "4357/4357 [==============================] - 626s 144ms/step - loss: 5.2070\n",
      "Epoch 78/250\n",
      "4357/4357 [==============================] - 626s 144ms/step - loss: 5.2132\n",
      "Epoch 79/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 5.2214\n",
      "Epoch 80/250\n",
      "4357/4357 [==============================] - 626s 144ms/step - loss: 5.2332\n",
      "Epoch 81/250\n",
      "4357/4357 [==============================] - 630s 145ms/step - loss: 5.2350\n",
      "Epoch 82/250\n",
      "4357/4357 [==============================] - 634s 146ms/step - loss: 5.2431\n",
      "Epoch 83/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 5.2507\n",
      "Epoch 84/250\n",
      "4357/4357 [==============================] - 632s 145ms/step - loss: 5.2579\n",
      "Epoch 85/250\n",
      "4357/4357 [==============================] - 630s 145ms/step - loss: 5.2670\n",
      "Epoch 86/250\n",
      "4357/4357 [==============================] - 624s 143ms/step - loss: 5.2735\n",
      "Epoch 87/250\n",
      "4357/4357 [==============================] - 632s 145ms/step - loss: 5.2777\n",
      "Epoch 88/250\n",
      "4357/4357 [==============================] - 625s 143ms/step - loss: 5.2903\n",
      "Epoch 89/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 5.2894\n",
      "Epoch 90/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 5.2954\n",
      "Epoch 91/250\n",
      "4357/4357 [==============================] - 638s 147ms/step - loss: 5.3126\n",
      "Epoch 92/250\n",
      "4357/4357 [==============================] - 644s 148ms/step - loss: 5.3211\n",
      "Epoch 93/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357/4357 [==============================] - 620s 142ms/step - loss: 5.3342\n",
      "Epoch 94/250\n",
      "4357/4357 [==============================] - 621s 142ms/step - loss: 5.3456\n",
      "Epoch 95/250\n",
      "4357/4357 [==============================] - 626s 144ms/step - loss: 5.3620\n",
      "Epoch 96/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 5.3698\n",
      "Epoch 97/250\n",
      "4357/4357 [==============================] - 622s 143ms/step - loss: 5.3725\n",
      "Epoch 98/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 5.3929\n",
      "Epoch 99/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 5.3996\n",
      "Epoch 100/250\n",
      "4357/4357 [==============================] - 634s 146ms/step - loss: 5.4072\n",
      "Epoch 101/250\n",
      "4357/4357 [==============================] - 625s 143ms/step - loss: 5.4196\n",
      "Epoch 102/250\n",
      "4357/4357 [==============================] - 629s 144ms/step - loss: 5.4265\n",
      "Epoch 103/250\n",
      "4357/4357 [==============================] - 635s 146ms/step - loss: 5.4300\n",
      "Epoch 104/250\n",
      "4357/4357 [==============================] - 625s 144ms/step - loss: 5.4398\n",
      "Epoch 105/250\n",
      "4357/4357 [==============================] - 632s 145ms/step - loss: 5.4541\n",
      "Epoch 106/250\n",
      "4357/4357 [==============================] - 637s 146ms/step - loss: 5.4611\n",
      "Epoch 107/250\n",
      "4357/4357 [==============================] - 629s 144ms/step - loss: 5.4716\n",
      "Epoch 108/250\n",
      "4357/4357 [==============================] - 647s 149ms/step - loss: 5.4846\n",
      "Epoch 109/250\n",
      "4357/4357 [==============================] - 619s 142ms/step - loss: 5.4999\n",
      "Epoch 110/250\n",
      "4357/4357 [==============================] - 625s 144ms/step - loss: 5.5117\n",
      "Epoch 111/250\n",
      "4357/4357 [==============================] - 602s 138ms/step - loss: 5.5203\n",
      "Epoch 112/250\n",
      "4357/4357 [==============================] - 584s 134ms/step - loss: 5.5304\n",
      "Epoch 113/250\n",
      "4357/4357 [==============================] - 2537s 582ms/step - loss: 5.5464\n",
      "Epoch 114/250\n",
      "4357/4357 [==============================] - 599s 138ms/step - loss: 5.5663\n",
      "Epoch 115/250\n",
      "4357/4357 [==============================] - 592s 136ms/step - loss: 5.5744\n",
      "Epoch 116/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 5.5797\n",
      "Epoch 117/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.5953\n",
      "Epoch 118/250\n",
      "4357/4357 [==============================] - 589s 135ms/step - loss: 5.6065\n",
      "Epoch 119/250\n",
      "4357/4357 [==============================] - 601s 138ms/step - loss: 5.6062\n",
      "Epoch 120/250\n",
      "4357/4357 [==============================] - 591s 136ms/step - loss: 5.6175\n",
      "Epoch 121/250\n",
      "4357/4357 [==============================] - 592s 136ms/step - loss: 5.6241\n",
      "Epoch 122/250\n",
      "4357/4357 [==============================] - 592s 136ms/step - loss: 5.6442\n",
      "Epoch 123/250\n",
      "4357/4357 [==============================] - 590s 135ms/step - loss: 5.6596\n",
      "Epoch 124/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.6821\n",
      "Epoch 125/250\n",
      "4357/4357 [==============================] - 593s 136ms/step - loss: 5.7005\n",
      "Epoch 126/250\n",
      "4357/4357 [==============================] - 590s 136ms/step - loss: 5.7048\n",
      "Epoch 127/250\n",
      "4357/4357 [==============================] - 591s 136ms/step - loss: 5.7170\n",
      "Epoch 128/250\n",
      "4357/4357 [==============================] - 587s 135ms/step - loss: 5.7318\n",
      "Epoch 129/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 5.7422\n",
      "Epoch 130/250\n",
      "4357/4357 [==============================] - 591s 136ms/step - loss: 5.7461\n",
      "Epoch 131/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.7478\n",
      "Epoch 132/250\n",
      "4357/4357 [==============================] - 591s 136ms/step - loss: 5.7505\n",
      "Epoch 133/250\n",
      "4357/4357 [==============================] - 592s 136ms/step - loss: 5.7648\n",
      "Epoch 134/250\n",
      "4357/4357 [==============================] - 598s 137ms/step - loss: 5.7793\n",
      "Epoch 135/250\n",
      "4357/4357 [==============================] - 595s 136ms/step - loss: 5.8000\n",
      "Epoch 136/250\n",
      "4357/4357 [==============================] - 594s 136ms/step - loss: 5.8153\n",
      "Epoch 137/250\n",
      "4357/4357 [==============================] - 590s 135ms/step - loss: 5.8276\n",
      "Epoch 138/250\n",
      "4357/4357 [==============================] - 586s 135ms/step - loss: 5.8364\n",
      "Epoch 139/250\n",
      "4357/4357 [==============================] - 574s 132ms/step - loss: 5.8543\n",
      "Epoch 140/250\n",
      "4357/4357 [==============================] - 595s 136ms/step - loss: 5.8710\n",
      "Epoch 141/250\n",
      "4357/4357 [==============================] - 603s 138ms/step - loss: 5.8855\n",
      "Epoch 142/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.8855\n",
      "Epoch 143/250\n",
      "4357/4357 [==============================] - 591s 136ms/step - loss: 5.9051\n",
      "Epoch 144/250\n",
      "4357/4357 [==============================] - 598s 137ms/step - loss: 5.9228\n",
      "Epoch 145/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.9409\n",
      "Epoch 146/250\n",
      "4357/4357 [==============================] - 644s 148ms/step - loss: 5.9589\n",
      "Epoch 147/250\n",
      "4357/4357 [==============================] - 598s 137ms/step - loss: 5.9746\n",
      "Epoch 148/250\n",
      "4357/4357 [==============================] - 600s 138ms/step - loss: 6.0081\n",
      "Epoch 149/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 6.0244\n",
      "Epoch 150/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 6.0460\n",
      "Epoch 151/250\n",
      "4357/4357 [==============================] - 599s 138ms/step - loss: 6.0672\n",
      "Epoch 152/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 6.0871\n",
      "Epoch 153/250\n",
      "4357/4357 [==============================] - 605s 139ms/step - loss: 6.1095\n",
      "Epoch 154/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 6.1252\n",
      "Epoch 155/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 6.1401\n",
      "Epoch 156/250\n",
      "4357/4357 [==============================] - 603s 138ms/step - loss: 6.1556\n",
      "Epoch 157/250\n",
      "4357/4357 [==============================] - 619s 142ms/step - loss: 6.1764\n",
      "Epoch 158/250\n",
      "4357/4357 [==============================] - 636s 146ms/step - loss: 6.1909\n",
      "Epoch 159/250\n",
      "4357/4357 [==============================] - 643s 148ms/step - loss: 6.2133\n",
      "Epoch 160/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 6.2092\n",
      "Epoch 161/250\n",
      "4357/4357 [==============================] - 646s 148ms/step - loss: 6.2133\n",
      "Epoch 162/250\n",
      "4357/4357 [==============================] - 644s 148ms/step - loss: 6.2256\n",
      "Epoch 163/250\n",
      "4357/4357 [==============================] - 649s 149ms/step - loss: 6.2410\n",
      "Epoch 164/250\n",
      "4357/4357 [==============================] - 650s 149ms/step - loss: 6.2491\n",
      "Epoch 165/250\n",
      "4357/4357 [==============================] - 644s 148ms/step - loss: 6.2589\n",
      "Epoch 166/250\n",
      "4357/4357 [==============================] - 647s 149ms/step - loss: 6.2612\n",
      "Epoch 167/250\n",
      "4357/4357 [==============================] - 645s 148ms/step - loss: 6.2739\n",
      "Epoch 168/250\n",
      "4357/4357 [==============================] - 642s 147ms/step - loss: 6.2820\n",
      "Epoch 169/250\n",
      "4357/4357 [==============================] - 654s 150ms/step - loss: 6.2900\n",
      "Epoch 170/250\n",
      "4357/4357 [==============================] - 651s 149ms/step - loss: 6.2969\n",
      "Epoch 171/250\n",
      "4357/4357 [==============================] - 643s 148ms/step - loss: 6.2977\n",
      "Epoch 172/250\n",
      "4357/4357 [==============================] - 652s 150ms/step - loss: 6.3023\n",
      "Epoch 173/250\n",
      "4357/4357 [==============================] - 649s 149ms/step - loss: 6.3249\n",
      "Epoch 174/250\n",
      "4357/4357 [==============================] - 650s 149ms/step - loss: 6.3344\n",
      "Epoch 175/250\n",
      "4357/4357 [==============================] - 662s 152ms/step - loss: 6.3514\n",
      "Epoch 176/250\n",
      "4357/4357 [==============================] - 645s 148ms/step - loss: 6.3652\n",
      "Epoch 177/250\n",
      "4357/4357 [==============================] - 649s 149ms/step - loss: 6.3818\n",
      "Epoch 178/250\n",
      "4357/4357 [==============================] - 648s 149ms/step - loss: 6.3702\n",
      "Epoch 179/250\n",
      "4357/4357 [==============================] - 645s 148ms/step - loss: 6.3837\n",
      "Epoch 180/250\n",
      "4357/4357 [==============================] - 650s 149ms/step - loss: 6.4051\n",
      "Epoch 181/250\n",
      "4357/4357 [==============================] - 648s 149ms/step - loss: 6.3938\n",
      "Epoch 182/250\n",
      "4357/4357 [==============================] - 645s 148ms/step - loss: 6.3873\n",
      "Epoch 183/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357/4357 [==============================] - 644s 148ms/step - loss: 6.4056\n",
      "Epoch 184/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 6.4024\n",
      "Epoch 185/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 6.4089\n",
      "Epoch 186/250\n",
      "4357/4357 [==============================] - 635s 146ms/step - loss: 6.4252\n",
      "Epoch 187/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 6.4046\n",
      "Epoch 188/250\n",
      "4357/4357 [==============================] - 629s 144ms/step - loss: 6.3948\n",
      "Epoch 189/250\n",
      "4357/4357 [==============================] - 636s 146ms/step - loss: 6.3744\n",
      "Epoch 190/250\n",
      "4357/4357 [==============================] - 630s 145ms/step - loss: 6.3571\n",
      "Epoch 191/250\n",
      "4357/4357 [==============================] - 641s 147ms/step - loss: 6.3609\n",
      "Epoch 192/250\n",
      "4357/4357 [==============================] - 635s 146ms/step - loss: 6.3387\n",
      "Epoch 193/250\n",
      "4357/4357 [==============================] - 630s 144ms/step - loss: 6.3160\n",
      "Epoch 194/250\n",
      "4357/4357 [==============================] - 639s 147ms/step - loss: 6.2985\n",
      "Epoch 195/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 6.2848\n",
      "Epoch 196/250\n",
      "4357/4357 [==============================] - 629s 144ms/step - loss: 6.2815\n",
      "Epoch 197/250\n",
      "4357/4357 [==============================] - 638s 146ms/step - loss: 6.2571\n",
      "Epoch 198/250\n",
      "4357/4357 [==============================] - 629s 144ms/step - loss: 6.2350\n",
      "Epoch 199/250\n",
      "4357/4357 [==============================] - 630s 145ms/step - loss: 6.2207\n",
      "Epoch 200/250\n",
      "4357/4357 [==============================] - 634s 145ms/step - loss: 6.2097\n",
      "Epoch 201/250\n",
      "4357/4357 [==============================] - 631s 145ms/step - loss: 6.1784\n",
      "Epoch 202/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 6.1527\n",
      "Epoch 203/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 6.1295\n",
      "Epoch 204/250\n",
      "4357/4357 [==============================] - 634s 145ms/step - loss: 6.1154\n",
      "Epoch 205/250\n",
      "4357/4357 [==============================] - 627s 144ms/step - loss: 6.0964\n",
      "Epoch 206/250\n",
      "4357/4357 [==============================] - 630s 145ms/step - loss: 6.0873\n",
      "Epoch 207/250\n",
      "4357/4357 [==============================] - 632s 145ms/step - loss: 6.0715\n",
      "Epoch 208/250\n",
      "4357/4357 [==============================] - 632s 145ms/step - loss: 6.0629\n",
      "Epoch 209/250\n",
      "4357/4357 [==============================] - 637s 146ms/step - loss: 6.0391\n",
      "Epoch 210/250\n",
      "4357/4357 [==============================] - 633s 145ms/step - loss: 6.0159\n",
      "Epoch 211/250\n",
      "4357/4357 [==============================] - 628s 144ms/step - loss: 5.9770\n",
      "Epoch 212/250\n",
      "4357/4357 [==============================] - 606s 139ms/step - loss: 5.9577\n",
      "Epoch 213/250\n",
      "4357/4357 [==============================] - 601s 138ms/step - loss: 5.9174\n",
      "Epoch 214/250\n",
      "4357/4357 [==============================] - 600s 138ms/step - loss: 5.8989\n",
      "Epoch 215/250\n",
      "4357/4357 [==============================] - 598s 137ms/step - loss: 5.8416\n",
      "Epoch 216/250\n",
      "4357/4357 [==============================] - 599s 137ms/step - loss: 5.8098\n",
      "Epoch 217/250\n",
      "4357/4357 [==============================] - 593s 136ms/step - loss: 5.7773\n",
      "Epoch 218/250\n",
      "4357/4357 [==============================] - 594s 136ms/step - loss: 5.7581\n",
      "Epoch 219/250\n",
      "4357/4357 [==============================] - 594s 136ms/step - loss: 5.7397\n",
      "Epoch 220/250\n",
      "4357/4357 [==============================] - 592s 136ms/step - loss: 5.7145\n",
      "Epoch 221/250\n",
      "4357/4357 [==============================] - 601s 138ms/step - loss: 5.6757\n",
      "Epoch 222/250\n",
      "4357/4357 [==============================] - 589s 135ms/step - loss: 5.6411\n",
      "Epoch 223/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.6218\n",
      "Epoch 224/250\n",
      "4357/4357 [==============================] - 594s 136ms/step - loss: 5.5902\n",
      "Epoch 225/250\n",
      "4357/4357 [==============================] - 591s 136ms/step - loss: 5.5812\n",
      "Epoch 226/250\n",
      "4357/4357 [==============================] - 601s 138ms/step - loss: 5.5542\n",
      "Epoch 227/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.5452\n",
      "Epoch 228/250\n",
      "4357/4357 [==============================] - 592s 136ms/step - loss: 5.5328\n",
      "Epoch 229/250\n",
      "4357/4357 [==============================] - 594s 136ms/step - loss: 5.4999\n",
      "Epoch 230/250\n",
      "4357/4357 [==============================] - 593s 136ms/step - loss: 5.4706\n",
      "Epoch 231/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.4402\n",
      "Epoch 232/250\n",
      "4357/4357 [==============================] - 589s 135ms/step - loss: 5.4188\n",
      "Epoch 233/250\n",
      "4357/4357 [==============================] - 598s 137ms/step - loss: 5.3864\n",
      "Epoch 234/250\n",
      "4357/4357 [==============================] - 587s 135ms/step - loss: 5.3691\n",
      "Epoch 235/250\n",
      "4357/4357 [==============================] - 603s 139ms/step - loss: 5.3479\n",
      "Epoch 236/250\n",
      "4357/4357 [==============================] - 607s 139ms/step - loss: 5.3300\n",
      "Epoch 237/250\n",
      "4357/4357 [==============================] - 580s 133ms/step - loss: 5.3134\n",
      "Epoch 238/250\n",
      "4357/4357 [==============================] - 596s 137ms/step - loss: 5.2929\n",
      "Epoch 239/250\n",
      "4357/4357 [==============================] - 604s 139ms/step - loss: 5.2810\n",
      "Epoch 240/250\n",
      "4357/4357 [==============================] - 601s 138ms/step - loss: 5.2398\n",
      "Epoch 241/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 5.2290\n",
      "Epoch 242/250\n",
      "4357/4357 [==============================] - 595s 137ms/step - loss: 5.1904\n",
      "Epoch 243/250\n",
      "4357/4357 [==============================] - 598s 137ms/step - loss: 5.1642\n",
      "Epoch 244/250\n",
      "4357/4357 [==============================] - 594s 136ms/step - loss: 5.1436\n",
      "Epoch 245/250\n",
      "4357/4357 [==============================] - 603s 138ms/step - loss: 5.1330\n",
      "Epoch 246/250\n",
      "4357/4357 [==============================] - 598s 137ms/step - loss: 5.1141\n",
      "Epoch 247/250\n",
      "4357/4357 [==============================] - 602s 138ms/step - loss: 5.0849\n",
      "Epoch 248/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.0664\n",
      "Epoch 249/250\n",
      "4357/4357 [==============================] - 597s 137ms/step - loss: 5.0501\n",
      "Epoch 250/250\n",
      "4357/4357 [==============================] - 594s 136ms/step - loss: 5.0261\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         1928600   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 256)        176640    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              296448    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 19286)             4956502   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,358,190\n",
      "Trainable params: 7,358,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, LSTM, Input, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "n_units = 128\n",
    "embedding_size = 100\n",
    "\n",
    "text_in = Input(shape= (None,))\n",
    "\n",
    "x = Embedding(total_words, embedding_size)(text_in)\n",
    "\n",
    "x = Bidirectional((GRU(n_units, return_sequences=True)))(x)\n",
    "x = Bidirectional(GRU(n_units) )(x)\n",
    "x=Dropout(0.2)(x)\n",
    "text_out=Dense(total_words, activation='softmax')(x)\n",
    "\n",
    "model=Model(text_in, text_out)\n",
    "\n",
    "#opti=RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"RMSprop\")\n",
    "\n",
    "epochs=250\n",
    "batch_size=32\n",
    "model.fit(X, y, epochs=epochs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xes6Ux-GzG-c"
   },
   "outputs": [],
   "source": [
    "#La temperatura sirve para hacer más determinista el modelo. Una temperatura alta\n",
    "#hace al modelo más diverso en las respuestas, mas sensible a los ejemplos\n",
    "#pero tambien mas propenso a los errores\n",
    "def sample_with_temp(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    #Se retorna el argumento con la probabilidad mas alta\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len, temp):\n",
    "    output_text = seed_text\n",
    "    seed_text = start_story + seed_text\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = token_list[-max_sequence_len:]\n",
    "        #print(token_list)\n",
    "        token_list = np.reshape(token_list, (1, max_sequence_len))\n",
    "        \n",
    "        probs = model.predict(token_list, verbose=0)[0]\n",
    "        y_class = sample_with_temp(probs, temperature = temp)\n",
    "        \n",
    "        output_word = tokenizer.index_word[y_class] if y_class>0 else ''\n",
    "        #Si se obtiene un \"|\" es que el modelo ya quiere terminar la historia\n",
    "        if output_word == \"|\":\n",
    "            break\n",
    "        seed_text += output_word + ' '\n",
    "        output_text += output_word + ' '          \n",
    "            \n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qI4WEizIzRcS"
   },
   "outputs": [],
   "source": [
    "seed_text = \"se que tu quieres que conmigo te vean y que la gente crea \"\n",
    "gen_words = 500\n",
    "temp = 1\n",
    "cancion = generate_text(seed_text, gen_words, model, seq_length, temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WZiAfgwOzRW8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'se que tu quieres que conmigo te vean y que la gente crea que le que le el temblaste  \\n  tu la conociste baby , me me , baby , me me que más y más que igual  \\n  que no le y le le le gusta hacer , no lo lo me da hacer  \\n  .  \\n  yo soy el que con mi canción  \\n  hasta el que se fue el tiempo  \\n  aunque es el que la cabeza \"  \\n  la vi , sigo solo su pesar que ( cuando le mete - la - el )  \\n  yo soy de un viaje ( oh - oh - oh - oh )  \\n  .  \\n  si me tiene mal de la luna , y tú no sé  \\n  de un día a ti  \\n  lo lo que tú tengo mí  \\n  tengo mí ( ¿qué ? )  \\n  porque tú te gusta la nota ( pa\\' pasar )  \\n  y se siente que me encanta con otro  \\n  no me te y te di un poco ( ¡duro ! )  \\n  con ella no acabe lo hago ni un par de que el pasado  \\n  y yo quisiera que to\\' el mundo te que te la imposible ?  \\n  yeah ! !  \\n  ya no hay salida , el sobreviviente  \\n  de angel : \"  \\n  los que te dé \"  \\n  la los que me vuelves  \\n  y si tu me vuelves a mí ( eso )  \\n  si me das todo el día de que te entregas .  \\n  por eso que se que habla que no me conoces  \\n  me lo que no me dejes no has y no  \\n  y no tengo que hablar de mí , te lo lo me tengo a llorar  \\n  yo quiero tenerte que no , no me duele  \\n  si se da pa\\' bailar contigo se le da con la mujer  \\n  que nos oponga en la disco me lo me me me la  \\n  de ti me vuelve loco  \\n  y si tu cuerpo me tiene de la que no me lo me da  \\n  .  \\n  me enamore de ti  \\n  sin ti solo tú me dices ( quiero lo que me siento )  \\n  que te amo y se acabe ya no me acabe  \\n  que estoy sintiendo  \\n  .  \\n  ( no hay la que el día de ser tu cara  \\n  que la luna está pa\\' que así ( tú )  \\n  pa\\' que tú quiere\\' hacer que tú te llegó la que no me  \\n  no te puedo ver  \\n  tal vez que quiere una mujer  \\n  contigo a mí me dices bien ( tú sabes bien , bien )  \\n  y yo sé que me conoces a ti no lo hago ( ella )  \\n  no me dejes pa\\' que la calle está pa\\' mí  \\n  nos vean nos vean  \\n  yo que a veces voy a llorar  \\n  no voy a llorar  \\n  tú no yo te voy a  \\n  y no te '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancion=cancion.replace('xoxo', ' \\n ')\n",
    "cancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "semilla = open(\"semillas.txt\",\"r\",encoding='ISO-8859-1')\n",
    "tem = [0.5,1,2]\n",
    "gen_words = 500\n",
    "todo = semilla.read()\n",
    "partes = todo.split(\"\\n\")\n",
    "for temp in tem:\n",
    "    cn = 0\n",
    "    for seed_text in partes:\n",
    "        arch = \"temperatura_\"+str(temp).replace(\".\",\",\")+\"cancion\"+str(cn)\n",
    "        #print(arch)\n",
    "        cancion = generate_text(seed_text, gen_words, model, seq_length, temp)\n",
    "        cancion=cancion.replace('xoxo', ' \\n ')\n",
    "        cn +=1\n",
    "        \n",
    "        lugar = open(\"canciones/\"+arch+\".txt\",\"w\",encoding='ISO-8859-1')\n",
    "        lugar.write(cancion)\n",
    "        lugar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "proyecto_blstm_word.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
